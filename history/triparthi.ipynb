{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcS_TxcFOgZR",
        "outputId": "b662d640-71f2-4dfb-f192-59e9da6364d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/180\n",
            "9/9 [==============================] - 6s 27ms/step - loss: 0.1169 - val_loss: 0.0592\n",
            "Epoch 2/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0522 - val_loss: 0.0279\n",
            "Epoch 3/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0160\n",
            "Epoch 4/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0102\n",
            "Epoch 5/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0053\n",
            "Epoch 6/180\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0023\n",
            "Epoch 7/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0010\n",
            "Epoch 8/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 5.7577e-04\n",
            "Epoch 9/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.5445e-04\n",
            "Epoch 10/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6798e-04 - val_loss: 3.2065e-04\n",
            "Epoch 11/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7061e-04 - val_loss: 2.6809e-04\n",
            "Epoch 12/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4771e-04 - val_loss: 2.3649e-04\n",
            "Epoch 13/180\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.7170e-04 - val_loss: 2.1934e-04\n",
            "Epoch 14/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.0638e-04 - val_loss: 2.1188e-04\n",
            "Epoch 15/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5754e-04 - val_loss: 1.9510e-04\n",
            "Epoch 16/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2332e-04 - val_loss: 1.7618e-04\n",
            "Epoch 17/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.8925e-04 - val_loss: 1.7223e-04\n",
            "Epoch 18/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6275e-04 - val_loss: 1.7285e-04\n",
            "Epoch 19/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3929e-04 - val_loss: 1.5590e-04\n",
            "Epoch 20/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1855e-04 - val_loss: 1.3810e-04\n",
            "Epoch 21/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0486e-04 - val_loss: 1.3232e-04\n",
            "Epoch 22/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1538e-05 - val_loss: 1.5238e-04\n",
            "Epoch 23/180\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6277e-05 - val_loss: 1.2193e-04\n",
            "Epoch 24/180\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.2394e-05 - val_loss: 1.1292e-04\n",
            "Epoch 25/180\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.6073e-05 - val_loss: 1.4378e-04\n",
            "Epoch 26/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8034e-05 - val_loss: 1.0275e-04\n",
            "Epoch 27/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5540e-05 - val_loss: 9.0867e-05\n",
            "Epoch 28/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9916e-05 - val_loss: 1.0260e-04\n",
            "Epoch 29/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0579e-05 - val_loss: 8.3286e-05\n",
            "Epoch 30/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2333e-05 - val_loss: 8.2462e-05\n",
            "Epoch 31/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9750e-05 - val_loss: 7.9520e-05\n",
            "Epoch 32/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6454e-05 - val_loss: 7.5984e-05\n",
            "Epoch 33/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3996e-05 - val_loss: 7.2396e-05\n",
            "Epoch 34/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2633e-05 - val_loss: 7.1258e-05\n",
            "Epoch 35/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0105e-05 - val_loss: 6.9287e-05\n",
            "Epoch 36/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8873e-05 - val_loss: 6.7724e-05\n",
            "Epoch 37/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6851e-05 - val_loss: 6.4141e-05\n",
            "Epoch 38/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5892e-05 - val_loss: 7.4959e-05\n",
            "Epoch 39/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5002e-05 - val_loss: 6.2193e-05\n",
            "Epoch 40/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4439e-05 - val_loss: 5.8590e-05\n",
            "Epoch 41/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1830e-05 - val_loss: 6.9231e-05\n",
            "Epoch 42/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1290e-05 - val_loss: 6.0140e-05\n",
            "Epoch 43/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0182e-05 - val_loss: 5.9623e-05\n",
            "Epoch 44/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9264e-05 - val_loss: 5.2188e-05\n",
            "Epoch 45/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8351e-05 - val_loss: 5.1419e-05\n",
            "Epoch 46/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8102e-05 - val_loss: 4.9247e-05\n",
            "Epoch 47/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7349e-05 - val_loss: 4.8414e-05\n",
            "Epoch 48/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5928e-05 - val_loss: 4.8565e-05\n",
            "Epoch 49/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6085e-05 - val_loss: 4.8144e-05\n",
            "Epoch 50/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5851e-05 - val_loss: 4.6168e-05\n",
            "Epoch 51/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5307e-05 - val_loss: 4.4316e-05\n",
            "Epoch 52/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3819e-05 - val_loss: 5.1261e-05\n",
            "Epoch 53/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3636e-05 - val_loss: 4.3237e-05\n",
            "Epoch 54/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3594e-05 - val_loss: 4.4506e-05\n",
            "Epoch 55/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3178e-05 - val_loss: 4.1165e-05\n",
            "Epoch 56/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2107e-05 - val_loss: 3.7274e-05\n",
            "Epoch 57/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2664e-05 - val_loss: 4.1543e-05\n",
            "Epoch 58/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1460e-05 - val_loss: 3.8603e-05\n",
            "Epoch 59/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0295e-05 - val_loss: 3.8161e-05\n",
            "Epoch 60/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0302e-05 - val_loss: 3.8432e-05\n",
            "Epoch 61/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0472e-05 - val_loss: 3.6152e-05\n",
            "Epoch 62/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8730e-06 - val_loss: 3.5772e-05\n",
            "Epoch 63/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6230e-06 - val_loss: 3.4562e-05\n",
            "Epoch 64/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0504e-06 - val_loss: 3.3348e-05\n",
            "Epoch 65/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5817e-06 - val_loss: 3.3812e-05\n",
            "Epoch 66/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0280e-06 - val_loss: 3.8703e-05\n",
            "Epoch 67/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8742e-06 - val_loss: 3.0873e-05\n",
            "Epoch 68/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4502e-06 - val_loss: 3.0069e-05\n",
            "Epoch 69/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9421e-06 - val_loss: 2.9305e-05\n",
            "Epoch 70/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3320e-06 - val_loss: 2.7848e-05\n",
            "Epoch 71/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0009e-06 - val_loss: 2.7594e-05\n",
            "Epoch 72/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3320e-06 - val_loss: 3.4319e-05\n",
            "Epoch 73/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3470e-06 - val_loss: 2.6665e-05\n",
            "Epoch 74/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7566e-06 - val_loss: 2.5452e-05\n",
            "Epoch 75/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7591e-06 - val_loss: 3.8811e-05\n",
            "Epoch 76/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2386e-06 - val_loss: 2.6058e-05\n",
            "Epoch 77/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1648e-06 - val_loss: 2.5518e-05\n",
            "Epoch 78/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1542e-06 - val_loss: 2.5135e-05\n",
            "Epoch 79/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7422e-06 - val_loss: 2.4878e-05\n",
            "Epoch 80/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7323e-06 - val_loss: 2.3969e-05\n",
            "Epoch 81/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0559e-06 - val_loss: 2.3218e-05\n",
            "Epoch 82/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7585e-06 - val_loss: 2.2314e-05\n",
            "Epoch 83/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5759e-06 - val_loss: 2.2109e-05\n",
            "Epoch 84/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4542e-06 - val_loss: 2.2005e-05\n",
            "Epoch 85/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2570e-06 - val_loss: 2.1488e-05\n",
            "Epoch 86/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7895e-06 - val_loss: 2.1543e-05\n",
            "Epoch 87/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3337e-06 - val_loss: 2.6431e-05\n",
            "Epoch 88/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2486e-06 - val_loss: 1.9864e-05\n",
            "Epoch 89/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2498e-06 - val_loss: 2.0378e-05\n",
            "Epoch 90/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8222e-06 - val_loss: 2.0962e-05\n",
            "Epoch 91/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8331e-06 - val_loss: 1.9925e-05\n",
            "Epoch 92/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6900e-06 - val_loss: 2.5567e-05\n",
            "Epoch 93/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6307e-06 - val_loss: 1.9599e-05\n",
            "Epoch 94/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8236e-06 - val_loss: 2.0223e-05\n",
            "Epoch 95/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6140e-06 - val_loss: 1.8419e-05\n",
            "Epoch 96/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6861e-06 - val_loss: 1.7972e-05\n",
            "Epoch 97/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1229e-06 - val_loss: 1.7728e-05\n",
            "Epoch 98/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8165e-06 - val_loss: 1.9335e-05\n",
            "Epoch 99/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5418e-06 - val_loss: 1.7527e-05\n",
            "Epoch 100/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1848e-06 - val_loss: 1.7299e-05\n",
            "Epoch 101/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9520e-06 - val_loss: 1.7247e-05\n",
            "Epoch 102/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6706e-06 - val_loss: 1.9617e-05\n",
            "Epoch 103/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3994e-06 - val_loss: 1.8179e-05\n",
            "Epoch 104/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8235e-06 - val_loss: 1.7319e-05\n",
            "Epoch 105/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6797e-06 - val_loss: 1.7347e-05\n",
            "Epoch 106/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7430e-06 - val_loss: 1.5290e-05\n",
            "Epoch 107/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2972e-06 - val_loss: 1.5936e-05\n",
            "Epoch 108/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1906e-06 - val_loss: 1.4884e-05\n",
            "Epoch 109/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9183e-06 - val_loss: 2.4435e-05\n",
            "Epoch 110/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1299e-06 - val_loss: 1.5936e-05\n",
            "Epoch 111/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5479e-06 - val_loss: 1.6300e-05\n",
            "Epoch 112/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4900e-06 - val_loss: 1.8358e-05\n",
            "Epoch 113/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6833e-06 - val_loss: 1.5151e-05\n",
            "Epoch 114/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5980e-06 - val_loss: 1.4974e-05\n",
            "Epoch 115/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3405e-06 - val_loss: 1.6728e-05\n",
            "Epoch 116/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3225e-06 - val_loss: 1.8381e-05\n",
            "Epoch 117/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8095e-06 - val_loss: 1.4099e-05\n",
            "Epoch 118/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0615e-06 - val_loss: 1.6733e-05\n",
            "Epoch 119/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2365e-06 - val_loss: 1.5573e-05\n",
            "Epoch 120/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1096e-06 - val_loss: 1.5322e-05\n",
            "Epoch 121/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6933e-06 - val_loss: 1.6041e-05\n",
            "Epoch 122/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2895e-06 - val_loss: 1.9304e-05\n",
            "Epoch 123/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3984e-06 - val_loss: 1.3822e-05\n",
            "Epoch 124/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4402e-06 - val_loss: 1.6004e-05\n",
            "Epoch 125/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8534e-06 - val_loss: 1.3500e-05\n",
            "Epoch 126/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2615e-06 - val_loss: 1.4968e-05\n",
            "Epoch 127/180\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0709e-06 - val_loss: 1.4816e-05\n",
            "Epoch 128/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1226e-06 - val_loss: 1.3779e-05\n",
            "Epoch 129/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5038e-06 - val_loss: 1.3741e-05\n",
            "Epoch 130/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7030e-06 - val_loss: 2.3396e-05\n",
            "Epoch 131/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8287e-06 - val_loss: 1.5618e-05\n",
            "Epoch 132/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4243e-06 - val_loss: 1.2189e-05\n",
            "Epoch 133/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1431e-06 - val_loss: 1.5724e-05\n",
            "Epoch 134/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2859e-06 - val_loss: 1.6135e-05\n",
            "Epoch 135/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6494e-06 - val_loss: 1.4909e-05\n",
            "Epoch 136/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7367e-06 - val_loss: 1.3164e-05\n",
            "Epoch 137/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7726e-06 - val_loss: 1.2764e-05\n",
            "Epoch 138/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5939e-06 - val_loss: 2.0131e-05\n",
            "Epoch 139/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6464e-06 - val_loss: 1.7577e-05\n",
            "Epoch 140/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5563e-06 - val_loss: 1.2507e-05\n",
            "Epoch 141/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2544e-06 - val_loss: 1.2386e-05\n",
            "Epoch 142/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8960e-06 - val_loss: 1.3296e-05\n",
            "Epoch 143/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7822e-06 - val_loss: 1.2667e-05\n",
            "Epoch 144/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9349e-06 - val_loss: 1.4442e-05\n",
            "Epoch 145/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6814e-06 - val_loss: 2.7200e-05\n",
            "Epoch 146/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8950e-06 - val_loss: 1.5242e-05\n",
            "Epoch 147/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4062e-06 - val_loss: 2.4553e-05\n",
            "Epoch 148/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1657e-06 - val_loss: 1.1271e-05\n",
            "Epoch 149/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8391e-06 - val_loss: 1.3598e-05\n",
            "Epoch 150/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0435e-06 - val_loss: 1.3624e-05\n",
            "Epoch 151/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2136e-06 - val_loss: 1.2203e-05\n",
            "Epoch 152/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3306e-06 - val_loss: 1.4003e-05\n",
            "Epoch 153/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3580e-06 - val_loss: 1.2878e-05\n",
            "Epoch 154/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2709e-06 - val_loss: 1.3667e-05\n",
            "Epoch 155/180\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3396e-06 - val_loss: 1.7270e-05\n",
            "Epoch 156/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8306e-06 - val_loss: 1.7594e-05\n",
            "Epoch 157/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9663e-06 - val_loss: 1.4752e-05\n",
            "Epoch 158/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3021e-06 - val_loss: 1.4614e-05\n",
            "Epoch 159/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6157e-06 - val_loss: 2.2483e-05\n",
            "Epoch 160/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1471e-05 - val_loss: 1.1823e-05\n",
            "Epoch 161/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0456e-06 - val_loss: 1.2252e-05\n",
            "Epoch 162/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2104e-06 - val_loss: 2.0884e-05\n",
            "Epoch 163/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0121e-06 - val_loss: 2.3841e-05\n",
            "Epoch 164/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1733e-06 - val_loss: 2.6362e-05\n",
            "Epoch 165/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3454e-06 - val_loss: 1.1999e-05\n",
            "Epoch 166/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4175e-06 - val_loss: 8.6719e-05\n",
            "Epoch 167/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5945e-05 - val_loss: 1.3278e-05\n",
            "Epoch 168/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0896e-06 - val_loss: 1.3739e-05\n",
            "Epoch 169/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9547e-06 - val_loss: 1.3622e-05\n",
            "Epoch 170/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3015e-05 - val_loss: 1.7613e-05\n",
            "Epoch 171/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1975e-05 - val_loss: 1.6569e-05\n",
            "Epoch 172/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6341e-06 - val_loss: 1.1122e-05\n",
            "Epoch 173/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9770e-06 - val_loss: 1.5484e-05\n",
            "Epoch 174/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5433e-06 - val_loss: 1.3005e-05\n",
            "Epoch 175/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7103e-06 - val_loss: 1.2064e-05\n",
            "Epoch 176/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1071e-06 - val_loss: 2.5160e-05\n",
            "Epoch 177/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6154e-06 - val_loss: 1.0621e-05\n",
            "Epoch 178/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2566e-06 - val_loss: 1.4619e-05\n",
            "Epoch 179/180\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0889e-06 - val_loss: 1.3651e-05\n",
            "Epoch 180/180\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0328e-06 - val_loss: 1.6309e-05\n",
            "3/3 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error: 5.278558694452684\n",
            "R-squared (R2) Score: 0.9997958443331312\n",
            "Mean Absolute Error (MAE): 1.3372335611979285\n",
            "Root Mean Squared Error (RMSE): 2.297511413345467\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import pickle\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('hv.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['Fitness Score'])\n",
        "y = df['Fitness Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)\n",
        "\n",
        "# Normalize the features\n",
        "scaler_X = MinMaxScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Normalize the target\n",
        "scaler_y = MinMaxScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "\n",
        "# Build the Neural Network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Nadam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train_scaled, epochs=180, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Make predictions\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_pred_scaled = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# Inverse transform to get values in the original range\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Calculate errors\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared (R2) Score: {r2}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "\n",
        "# Save the trained model to an HDF5 file\n",
        "model.save('techne_ANN.h5')\n",
        "\n",
        "# Save the scalers to pickle files\n",
        "with open('scaler_X.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler_X, f)\n",
        "\n",
        "with open('scaler_y.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler_y, f)\n"
      ]
    }
  ]
}